{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb53707f-fe63-4ed9-b8a0-85f762872c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30a8012-51da-4bbb-a7ee-320aaff4f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1eac73c-6185-47e5-a2b5-673de70106ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f2a691-78a2-431e-b29c-c7eb1d2b55c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/oam/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/patrick/anaconda3/envs/oam/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from autoencoder import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64da396-abc8-4896-949d-8895132b8499",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Autoencoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0bdd2cc-fe00-4d93-8a17-b0321480fcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import get_split_df\n",
    "from torchvision.transforms import Resize, ToTensor\n",
    "\n",
    "resize = Resize((224))\n",
    "to_tensor = ToTensor()\n",
    "\n",
    "transforms = [to_tensor, resize]\n",
    "\n",
    "train_dataset, test_dataset = get_split_df('df.csv', \n",
    "                                           transform=transforms, \n",
    "                                           target_transform=transforms, \n",
    "                                           stds=[0.1, 0.01])\n",
    "\n",
    "len(train_dataset) + len(test_dataset) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ca623d2-32bd-4385-8cb1-bbe69233033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 12\n",
    "\n",
    "dataloader_kwargs = {'batch_size': bs, \n",
    "                     'num_workers': 4,\n",
    "                     'prefetch_factor': 2,\n",
    "                     'persistent_workers': True,\n",
    "                     'shuffle': True, \n",
    "                     'pin_memory': False}\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, **dataloader_kwargs)\n",
    "test_dataloader = DataLoader(test_dataset, **dataloader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7aaacf7-8656-44ac-98b4-cb3ca6fd1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class run_logger():\n",
    "\n",
    "    def __init__(self,\n",
    "                **kwargs):\n",
    "                     \n",
    "        self._init(**kwargs)\n",
    "        \n",
    "\n",
    "    def _init(self,\n",
    "             run_id, \n",
    "             n_epoch, \n",
    "             n_iter_train, \n",
    "             n_iter_test):\n",
    "                 \n",
    "        self.run_id = run_id\n",
    "        \n",
    "        self.log_dir = os.path.join(f'logs/{self.run_id}')\n",
    "        os.makedirs(self.log_dir, exist_ok=False)\n",
    "        \n",
    "        self.train_loss_matrix = np.zeros((n_epoch, n_iter_train))\n",
    "        self.train_losses_outpath = os.path.join(self.log_dir, 'train_losses.npy')\n",
    "        \n",
    "        self.test_loss_matrix = np.zeros((n_epoch, n_iter_test))\n",
    "        self.test_losses_outpath = os.path.join(self.log_dir, 'test_losses.npy')\n",
    "\n",
    "    def save_losses(self):\n",
    "        np.save(self.train_losses_outpath, self.train_loss_matrix)\n",
    "        np.save(self.test_losses_outpath, self.test_loss_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a90b5b5-d5e5-4e65-9430-44cc7a88eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction losses:\n",
    "# https://research.nvidia.com/sites/default/files/pubs/2017-03_Loss-Functions-for/NN_ImgProc.pdf\n",
    "MSE = torch.nn.MSELoss()\n",
    "MAE = torch.nn.L1Loss()\n",
    "criterion = MAE\n",
    "\n",
    "opt = torch.optim.Adam(a.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7563b4d4-beab-43e2-8963-caca30462f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f12211e-c10e-41e9-b5b4-f7c65daea2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 56\n",
    "\n",
    "run_id = str(uuid4())\n",
    "logger = run_logger(run_id=run_id, \n",
    "                    n_epoch=n_epoch, \n",
    "                    n_iter_train=len(train_dataloader), \n",
    "                    n_iter_test=len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1e1d6c9-4209-4888-a079-1f48576f065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [0/56]:   4%|‚ñç         | 16/360 [00:11<04:16,  1.34it/s, MSE_train=0.0823, criterion=MAE, lr=0.0003]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loop):\n\u001b[1;32m     14\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "change_strategy_window = 50\n",
    "lr_rrf = 0.95\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    a = a.train(True)\n",
    "    \n",
    "    train_loop = tqdm(train_dataloader)\n",
    "\n",
    "    # latest_lr = opt.defaults['lr']\n",
    "\n",
    "    # TRAIN LOOP\n",
    "    for i, (x, y) in enumerate(train_loop):\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        if len(x.shape) > 4:\n",
    "            \n",
    "            x = x.reshape((-1, 3, 224, 224))\n",
    "            y = y.reshape((-1, 3, 224, 224))\n",
    "            \n",
    "        out = a(y)\n",
    "        \n",
    "        batch_MSE = MSE(out, x)\n",
    "        batch_loss = criterion(out, x) if criterion == MAE else batch_MSE\n",
    "        \n",
    "        logger.train_loss_matrix[epoch][i] = batch_MSE.item()\n",
    "\n",
    "        # # Change strategy if the loss hasn't dropped within a window of batches\n",
    "        # if i>change_strategy_window:\n",
    "        #     if logger.train_loss_matrix[epoch][i-change_strategy_window:i].min() == logger.train_loss_matrix[epoch][i-change_strategy_window]:\n",
    "        #         opt.defaults['lr'] *= lr_rrf\n",
    "\n",
    "        batch_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        train_loop.set_description(f\"Epoch [{epoch}/{n_epoch}]\")\n",
    "        train_loop.set_postfix({'MSE_train': np.mean(logger.train_loss_matrix[epoch][logger.train_loss_matrix[epoch]>0]),\n",
    "                         'criterion': 'MSE' if criterion == MSE else 'MAE',\n",
    "                         'lr': opt.defaults['lr']})\n",
    "\n",
    "    \n",
    "    # TEST LOOP\n",
    "    a = a.train(False)\n",
    "    \n",
    "    test_loop = tqdm(test_dataloader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(test_loop):\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out = a(y)\n",
    "            \n",
    "            test_batch_loss = MSE(out, x)\n",
    "            logger.test_loss_matrix[epoch][i] = test_batch_loss.item()\n",
    "    \n",
    "            test_loop.set_description(f\"Epoch [{epoch}/{n_epoch}]\")\n",
    "            test_loop.set_postfix({'MSE_test': np.mean(logger.test_loss_matrix[epoch][logger.test_loss_matrix[epoch]>0]),})\n",
    "\n",
    "    \n",
    "    epoch_test_loss = np.mean(logger.test_loss_matrix[epoch])\n",
    "\n",
    "    # Save this model if it had the best mean test loss\n",
    "    if np.argmin(np.mean(logger.test_loss_matrix[:epoch+1], axis=-1)) == epoch:\n",
    "        model_out_path = os.path.join(logger.log_dir, 'best.pt')\n",
    "        torch.save(a.state_dict(), model_out_path)\n",
    "        print(f'saving best, MSE_test: {epoch_test_loss:.6f}')\n",
    "    else:\n",
    "        # opt.defaults['lr'] = latest_lr\n",
    "        criterion = MSE if criterion == MAE else MAE\n",
    "        opt.defaults['lr'] *= 0.75\n",
    "\n",
    "    logger.save_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647b9cc-b2df-4165-b728-c2c3335ba4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=bs, ncols=3, figsize=(12,4*bs))\n",
    "\n",
    "a.train(False)\n",
    "a.load_state_dict(torch.load(model_out_path))\n",
    "\n",
    "x, y = next(iter(test_dataloader))\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "out = a(y)\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "\n",
    "    _x = x[i].permute(1,2,0).cpu().detach().numpy()\n",
    "    _out = out[i].permute(1,2,0).cpu().detach().numpy()\n",
    "    _y = y[i].permute(1,2,0).cpu().detach().numpy()\n",
    "    \n",
    "    ax[i][0].imshow(_x)\n",
    "    ax[i][1].imshow(_out)\n",
    "    ax[i][2].imshow(_y)\n",
    "    \n",
    "    ax[i][0].set_title('x')\n",
    "    ax[i][1].set_title('x_prime')\n",
    "    ax[i][2].set_title('y')\n",
    "    \n",
    "    ax[i][0].axis('off')\n",
    "    ax[i][1].axis('off')\n",
    "    ax[i][2].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97cc09f-c875-4129-a82b-9a5be2032932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
